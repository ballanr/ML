{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dade22c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "Note:\n",
    "</b> \n",
    "Following along with the book but condensing and making my own changes.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f412c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef07ef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.5.0\n",
      "Keras version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff9908",
   "metadata": {},
   "source": [
    "# Generating Shakespearean text using a Character RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16962d8b",
   "metadata": {},
   "source": [
    "### Creating the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab222cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = 'https://homl.info/shakespeare'\n",
    "filepath = keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24de8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level = True)\n",
    "tokenizer.fit_on_texts([shakespeare_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1a62697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['First'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d776eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58382208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of distinct characters\n",
    "max_id = len(tokenizer.word_index)\n",
    "\n",
    "# Set values to 0 index\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd1c4c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>\n",
    "Note:\n",
    "</b> \n",
    "For some reason the attribute `tokenizer.document_count` evaluates to 1 now, so we have to get the total number of words a slightly different way.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8da5a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total character count\n",
    "dataset_size = len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a38b0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset in TensorFlow\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69506d2a",
   "metadata": {},
   "source": [
    "### Chopping the sequential dataset into multiple windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1efb2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows\n",
    "window_length = 101\n",
    "dataset = dataset.window(window_length, shift = 1, drop_remainder = True)\n",
    "\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "\n",
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth = max_id), y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c04c46",
   "metadata": {},
   "source": [
    "### Building and training the Char-RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "867a114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:04:36.525013: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-12 12:04:37.473087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-12 12:04:37.967199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-12 12:04:38.484194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-12 12:04:43.945049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31368/31368 [==============================] - 6338s 202ms/step - loss: 2.86106314s 201ms/step - loss: 2.86 - 631\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.GRU(128, return_sequences = True, input_shape = [None, max_id], \n",
    "#                                                  dropout = 0.2, recurrent_dropout = 0.2),\n",
    "                                                  dropout = 0.2),\n",
    "                                keras.layers.GRU(128, return_sequences = True, input_shape = [None, max_id], \n",
    "#                                                  dropout = 0.2, recurrent_dropout = 0.2), \n",
    "                                                 dropout = 0.2),\n",
    "                                keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation = 'softmax'))])\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')\n",
    "history = model.fit(dataset, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84aff3",
   "metadata": {},
   "source": [
    "### Using the Char-RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bed37e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8864335664335664"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6338/7150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0532f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    x = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(x, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe38aa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = preprocess(['How are yo'])\n",
    "# y_pred = model.predict_classes(x_new)\n",
    "y_pred = np.argmax(model.predict(x_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(y_pred + 1)[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128dcfb",
   "metadata": {},
   "source": [
    "### Generating fake Shakespearean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e973e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature = 1):\n",
    "    x_new = preprocess([text])\n",
    "    y_proba = model.predict(x_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba)\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples = 1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5814b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars = 50, temperature = 1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fe24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text('t', temperature = 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text('w', temperature = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text('w', temperature = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa662120",
   "metadata": {},
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift = 100, drop_remainder = True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(100))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(lambda x_batch, y_batch: (tf.one_hot(x_batch, depth = max_id), y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keeras.models.Sequential([keras.layers.GRU(128, return_sequences = True, \n",
    "                                                   stateful = True, dropout = 0.2, \n",
    "                                                   batch_input_shape = [batch_size, None, max_id]), \n",
    "                                  keras.layers.GRU(128, return_sequences = True, stateful = True, \n",
    "                                                   dropout = 0.2), \n",
    "                                  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation = 'softmax'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')\n",
    "model.fit(dataset, epochs = 50, callback = [ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1edc6e",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828278e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefc47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c847c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf675c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa4a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42299e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
